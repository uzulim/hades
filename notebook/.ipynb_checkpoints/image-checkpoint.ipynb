{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunghyunlim/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from scipy.linalg import svd\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.stats import pearsonr as rcoef\n",
    "from scipy import fftpack as fft\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "from hades import misc\n",
    "from hades import Hades, hp_grid\n",
    "from misc import plot_filt, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_save_mnist(data_dir, X_name, z_name, download=False):\n",
    "    # Import data\n",
    "    dataset = datasets.MNIST(root=data_dir, download=download, train=True, transform=transforms.ToTensor())\n",
    "    loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=False)\n",
    "    X = [] # Image data\n",
    "    z = [] # Label\n",
    "    for item in dataset:\n",
    "        X.append(np.array(item[0]))\n",
    "        z.append(item[1])\n",
    "    X = np.concatenate(X, axis = 0)\n",
    "    z = np.array(z)\n",
    "    np.save(data_dir+'/'+X_name, X)\n",
    "    np.save(data_dir+'/'+z_name, z)\n",
    "    \n",
    "\n",
    "def import_save_fmnist(data_dir, X_name, z_name, download=False):\n",
    "    # Import data\n",
    "    dataset = datasets.FashionMNIST(root=data_dir, download=download, train=True, transform=transforms.ToTensor())\n",
    "    loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=False)\n",
    "    X = [] # Image data\n",
    "    z = [] # Label\n",
    "    for item in dataset:\n",
    "        X.append(np.array(item[0]))\n",
    "        z.append(item[1])\n",
    "    X = np.concatenate(X, axis = 0)\n",
    "    z = np.array(z)\n",
    "    np.save(data_dir+'/'+X_name, X)\n",
    "    np.save(data_dir+'/'+z_name, z)\n",
    "    \n",
    "\n",
    "def import_save_face(data_dir, X_name, z_name, download=False):\n",
    "    lfw_people = fetch_lfw_people(min_faces_per_person=50, resize=0.5)\n",
    "    X = lfw_people.images\n",
    "    z = lfw_people['target']\n",
    "    np.save(data_dir+'/'+X_name, X)\n",
    "    np.save(data_dir+'/'+z_name, z)\n",
    "    \n",
    "    \n",
    "def split_by_class(X, z):\n",
    "    classes = np.sort(list(set(z)))\n",
    "    inds_cls = [np.nonzero(z==i)[0] for i in classes]\n",
    "    X_split = [X[item] for item in inds_cls]\n",
    "    return (X_split, classes)\n",
    "\n",
    "\n",
    "def dct(X, dct_thr):\n",
    "    X_dct = fft.dctn(X, axes = (1, 2)) # Discrete cosine transform\n",
    "    X_dct = X_dct[:, :dct_thr, :dct_thr]\n",
    "    X_flat = X_dct.reshape(X_dct.shape[0], dct_thr * dct_thr)\n",
    "    return X_flat\n",
    "\n",
    "\n",
    "def process_input(X, z, dct_thr):\n",
    "    X_d = dct(X, dct_thr)\n",
    "    X_sp, _ = split_by_class(X, z)\n",
    "    X_dsp, _ = split_by_class(X_d, z)\n",
    "    return {'X_d': X_d, 'X_sp': X_sp, 'X_dsp': X_dsp}\n",
    "\n",
    "\n",
    "def gallery_extreme(X_img, X_dsp, scores, classes, n_ext, \n",
    "                    fig_scale=1.5, save_fig=True,\n",
    "                    wspace=0.03, hspace=0.03, fig_name='untitled'):\n",
    "    n_classes = classes.size\n",
    "    nrows = n_classes\n",
    "    ncols = 2 * n_ext\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    fig.set_size_inches(fig_scale * ncols, fig_scale * nrows)\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "\n",
    "    for i in range(nrows):\n",
    "        X = X_dsp[i]\n",
    "        sco = scores[i]\n",
    "        inds_sort = np.argsort(sco).astype(int)\n",
    "        inds_high = inds_sort[-n_ext:]\n",
    "        inds_low = inds_sort[:n_ext]\n",
    "        \n",
    "        imgs_high = X_img[i][inds_high]\n",
    "        imgs_low = X_img[i][inds_low]\n",
    "        for j in range(n_ext):\n",
    "            ax[i, j].imshow(imgs_low[j], cmap='gray')\n",
    "            ax[i, j+n_ext].imshow(imgs_high[j], cmap='gray')\n",
    "    \n",
    "    plt.savefig('output/' + fig_name + '.pdf')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runthrough(X_img, z, dct_thr, cls, hp=None, train_prop=1.0):\n",
    "    # Process X_d, X_sp, X_dsp\n",
    "    print('Processing input.')\n",
    "    processed_input = process_input(X_img, z, dct_thr)\n",
    "    X_d = processed_input['X_d']\n",
    "    X_sp = processed_input['X_sp']\n",
    "    X_dsp = processed_input['X_dsp']\n",
    "    \n",
    "    # Train classifier\n",
    "    print(f'Training classifiers.')\n",
    "    clfs = [Hades() for i in cls]\n",
    "    # hp = hp_grid(k=100)\n",
    "    for i in cls:\n",
    "        print(f'Doing {i}...')\n",
    "        clfs[i].fit(X_dsp[i], hp=hp, probe_prop=train_prop)\n",
    "\n",
    "    # Evaluate singularity score\n",
    "    print(f'Scoring...')\n",
    "    scores = [clfs[i].score_samples(X_dsp[i]) for i in cls]\n",
    "    \n",
    "    return {'X_img': X_img,\n",
    "            'z': z,\n",
    "            'processed_input': processed_input,\n",
    "            'clfs': clfs,\n",
    "            'scores': scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = False\n",
    "convert_into_numpy = False\n",
    "if convert_into_numpy:\n",
    "    import_save_mnist(data_dir, 'mnist_X.npy', 'mnist_z.npy', download=download_data)\n",
    "    import_save_fmnist(data_dir, 'fmnist_X.npy', 'fmnist_z.npy', download=download_data)\n",
    "    import_save_face(data_dir, 'face_X.npy', 'face_z.npy', download=download_data)\n",
    "    \n",
    "timestamp_now = misc.timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "data_dir = 'data'\n",
    "X_name = 'mnist_X.npy'\n",
    "z_name = 'mnist_z.npy'\n",
    "cls = np.arange(10)\n",
    "dct_thr = 10\n",
    "hp = hp_grid(k=100)\n",
    "train_prop = 1.0\n",
    "# Display setting\n",
    "fig_n_ext = 5\n",
    "fig_scale = 1.5\n",
    "\n",
    "# Runthrough\n",
    "X_img = np.load(data_dir+'/'+X_name)\n",
    "z = np.load(data_dir+'/'+z_name)\n",
    "output = runthrough(X_img, z, dct_thr, cls, hp=hp, train_prop=train_prop)\n",
    "\n",
    "# Display output\n",
    "X_sp=output['processed_input']['X_sp']\n",
    "X_dsp=output['processed_input']['X_dsp']\n",
    "scores=output['scores']\n",
    "fig_name = f'MNIST {timestamp_now}'\n",
    "gallery_extreme(X_sp, X_dsp, scores, classes=cls, n_ext=fig_n_ext, fig_scale=fig_scale, fig_name=fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_times = [item.fit_time for item in output['clfs']]\n",
    "(y_min, y_max) = (0, 2 * np.max(fit_times))\n",
    "plt.ylim([y_min, y_max])\n",
    "plt.suptitle(f'Fit time for MNIST, per class')\n",
    "plt.plot(fit_times, marker = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "data_dir = 'data'\n",
    "X_name = 'fmnist_X.npy'\n",
    "z_name = 'fmnist_z.npy'\n",
    "cls = np.arange(10)\n",
    "dct_thr = 10\n",
    "hp = hp_grid(k=100)\n",
    "train_prop = 1.0\n",
    "# Display setting\n",
    "fig_n_ext = 5\n",
    "fig_scale = 1.5\n",
    "\n",
    "# Runthrough\n",
    "X_img = np.load(data_dir+'/'+X_name)\n",
    "z = np.load(data_dir+'/'+z_name)\n",
    "output = runthrough(X_img, z, dct_thr, cls, hp=hp, train_prop=train_prop)\n",
    "\n",
    "# Display output\n",
    "X_sp=output['processed_input']['X_sp']\n",
    "X_dsp=output['processed_input']['X_dsp']\n",
    "scores=output['scores']\n",
    "fig_name = f'FMNIST {timestamp_now}'\n",
    "gallery_extreme(X_sp, X_dsp, scores, classes=cls, n_ext=fig_n_ext, fig_scale=fig_scale, fig_name=fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_times = [item.fit_time for item in output['clfs']]\n",
    "(y_min, y_max) = (0, 2 * np.max(fit_times))\n",
    "plt.ylim([y_min, y_max])\n",
    "plt.suptitle(f'Fit time for FashionMNIST, per class')\n",
    "plt.plot(fit_times, marker = 'o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
